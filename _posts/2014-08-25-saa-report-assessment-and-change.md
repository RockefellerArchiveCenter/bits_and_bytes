---
id: 1161
title: 'SAA Report: Assessment and Change'
date: 2014-08-25T12:04:20+00:00
author: Hillel Arnold
layout: post
redirect_from: /?p=1161
categories:
  - Conferences/Education
tags:
  - Aeon
  - assessment
  - conferences
  - SAA
  - user experience
excerpt_separator: <!--more-->
---
One of the sessions I found most intriguing at this year's SAA Annual Meeting was "[How Are We Doing? Improving Access Through Assessment](http://archives2014.sched.org/event/4f1b651f77638e11f0d80fda214ef9f9)," which discussed a variety of tools and methodologies for quantifying information about users, collections and discovery tools, as well as how gathering that data can help us improve our users' experience.<!--more-->

The first set of presenters – [Jocelyn Wilk](http://archives2014.sched.org/speaker/jocwilk) and [Carrie Hintz](http://archives2014.sched.org/speaker/ceh2148) – talked about Columbia University's user services assessment project, which was driven by changes and growth in their organizational structure, and an ensuing need to understand the effects of those changes on their users. The project took the shape of a year-long survey which had the immediate goals of understanding users needs and experience and evaluating the service offered, as well as the long-term goals of finding more strategic ways of collecting data, and establishing an iterative, sustainable assessment strategy.

In order to develop the survey, they started by asking very basic questions - what do we know, what don't we know, and what do we want to know – and then worked to create more formal questions, methodologies and audiences for each area. They also made extensive use of the [Archival Metrics Project](http://archivalmetrics.org/), which is something I'd heard about but regretfully had not paid much attention to in the past.

Following up on this, [Christian Dupont](http://archives2014.sched.org/speaker/cdupont) (who we know through Atlas Systems/Aeon, but who is moving to Boston College shortly) gave an excellent overview of professional literature on assessment in archives, highlighting a lack of standards development around reference services. It looks like this is changing, though, not only with the Archival Metrics Project, but also with a [number](http://www.oclc.org/content/dam/research/publications/library/2010/2010-11.pdf?urlm=162945) of [studies](http://www.academia.edu/485594/Whats_So_Special_About_Special_Collections_Or_Assessing_the_Value_Special_Collections_Bring_to_Academic_Libraries) devoted to the topic. I was also excited to learn of the [RBMS Metrics and Assessment Task Force](http://www.rbms.info/committees/task_force/metrics_assessment/), which has now morphed into a [Joint Task Force on Public Services Metrics with SAA and ACRL](http://www2.archivists.org/governance/handbook/section7/groups/SAA-ACRL-RBMS-Joint-Task-Force-on-Public-Services-Metrics).

Overall, the very clear message from this panel was that assessment is not just about gathering numbers; it's about creating an organizational culture where measurement is valued, but more importantly where change based on the lessons those measurements teaches us is effected.
